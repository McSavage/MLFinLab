{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e8a8ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of barrier_events: (89, 5)\n",
      "NaN counts in barrier_events:\n",
      "t1      0\n",
      "trgt    0\n",
      "side    0\n",
      "pt      0\n",
      "sl      0\n",
      "dtype: int64\n",
      "\n",
      "First few rows:\n",
      "                                             t1      trgt  side  pt  sl\n",
      "2015-01-07 16:55:16.638 2015-01-08 01:48:57.964  0.006039   1.0   1   2\n",
      "2015-01-08 01:48:57.964 2015-01-08 18:11:19.540  0.008445   1.0   1   2\n",
      "2015-01-08 15:00:21.581 2015-01-09 15:02:59.709  0.007834   1.0   1   2\n",
      "2015-01-08 18:11:19.540 2015-01-09 18:14:11.989  0.007365   1.0   1   2\n",
      "2015-01-09 14:29:19.229 2015-01-09 16:17:00.682  0.006032   1.0   1   2\n",
      "\n",
      "Shape after dropping NaN: (89, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 11:05:19.030936 100.0% apply_pt_sl_on_t1 done after 0.03 minutes. Remaining 0.0 minutes..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 70, 42, 79]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Thisi example is adapted from Hudson and Thames\n",
    "https://hudson-and-thames-mlfinlab-premium.readthedocs-hosted.com/en/latest/sampling/sequential_boot.html\n",
    " \n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mlfinlab.util import volatility\n",
    "from mlfinlab.filters import filters\n",
    "from mlfinlab.labeling import labeling\n",
    "from mlfinlab.sampling import bootstrapping\n",
    "from mlfinlab.sampling import concurrent\n",
    "from mlfinlab.data_structures import standard_data_structures\n",
    "\n",
    "'''-----------------------------------------------------------------------------------'''\n",
    "# sp_read = pd.read_csv('../data/SP.csv')\n",
    "# sp = sp_read.loc[pd.to_datetime(sp_read['date'].astype(str)) >= pd.Timestamp('2011-01-01')].copy()\n",
    "# sp['date_time'] = pd.to_datetime(sp['date'].astype(str) + ' ' + sp['time'].astype(str))\n",
    "# sp['date'] = sp['date_time'].dt.normalize()\n",
    "# sp['date_time'] = pd.to_datetime(sp['date'].astype(str) + ' ' + sp['time'].astype(str))\n",
    "# sp_processed = sp[['date_time', 'price', 'volume']].copy()\n",
    "# sp_processed.columns = ['date_time', 'price', 'volume']\n",
    "\n",
    "# data = standard_data_structures.get_dollar_bars(\n",
    "#     sp_processed, threshold=1000000, batch_size=100000, verbose=False\n",
    "# )\n",
    "'''-----------------------------------------------------------------------------------'''\n",
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/hudson-and-thames/example-data/main/dollar_bars.csv\"\n",
    ")\n",
    "data = data.iloc[:2000, :]  # slice the dataset so example doesn't run too long\n",
    "data.index = pd.to_datetime(data[\"date_time\"])\n",
    "data = data.drop(\"date_time\", axis=1)\n",
    "'''-----------------------------------------------------------------------------------'''\n",
    "\n",
    "data = data.iloc[:2000, :]  # slice the dataset so example doesn't run too long\n",
    "#data.index = pd.to_datetime(data[\"date_time\"])\n",
    "#data = data.drop(\"date_time\", axis=1)-\n",
    "# Select the data from 1st September 2011\n",
    "pdata1 = data.copy()\n",
    "\n",
    "data = data[\"2011-09-01\":]\n",
    "# Based on the simple moving average cross-over strategy.\n",
    "# Compute moving averages\n",
    "fast_window = 20\n",
    "slow_window = 50\n",
    "data[\"fast_mavg\"] = (\n",
    "     data[\"close\"]\n",
    "     .rolling(window=fast_window, min_periods=fast_window, center=False)\n",
    "     .mean()\n",
    " )\n",
    "data[\"slow_mavg\"] = (\n",
    "     data[\"close\"]\n",
    "     .rolling(window=slow_window, min_periods=slow_window, center=False)\n",
    "     .mean()\n",
    ")\n",
    "# Compute sides\n",
    "data[\"side\"] = np.nan\n",
    "long_signals = data[\"fast_mavg\"] >= data[\"slow_mavg\"]\n",
    "short_signals = data[\"fast_mavg\"] < data[\"slow_mavg\"]\n",
    "data.loc[long_signals, \"side\"] = 1\n",
    "data.loc[short_signals, \"side\"] = -1\n",
    "# Remove Look ahead biase by lagging the signal\n",
    "data[\"side\"] = data[\"side\"].shift(1)\n",
    "# Duplicate the raw data\n",
    "raw_data = data.copy()\n",
    "# Drop the NaN values from our data set\n",
    "data.dropna(axis=0, how=\"any\", inplace=True)\n",
    "# Compute daily volatility\n",
    "daily_vol = volatility.get_daily_vol(close=data[\"close\"], lookback=50)\n",
    "# Apply Symmetric CUSUM filter and get timestamps for events\n",
    "# Note: Only the CUSUM filter needs a point estimate for volatility\n",
    "cusum_events = filters.cusum_filter(\n",
    "     data[\"close\"], threshold=daily_vol[\"2011-09-01\":\"2018-01-01\"].mean()\n",
    ")\n",
    "# Compute (triple barrier labeling) vertical barrier\n",
    "vertical_barriers = labeling.add_vertical_barrier(\n",
    "     t_events=cusum_events, close=data[\"close\"], num_days=1\n",
    ")\n",
    "pt_sl = [1, 2]\n",
    "min_ret = 0.005\n",
    "barrier_events = labeling.get_events(\n",
    "     close=data[\"close\"],\n",
    "     t_events=cusum_events,\n",
    "     pt_sl=pt_sl,\n",
    "     target=daily_vol,\n",
    "     min_ret=min_ret,\n",
    "     num_threads=3,\n",
    "     vertical_barrier_times=vertical_barriers,\n",
    "     side_prediction=data[\"side\"],\n",
    ")\n",
    "barrier_events\n",
    "\n",
    "# Check for NaN values\n",
    "print(f\"Shape of barrier_events: {barrier_events.shape}\")\n",
    "print(f\"NaN counts in barrier_events:\\n{barrier_events.isna().sum()}\")\n",
    "print(f\"\\nFirst few rows:\\n{barrier_events.head()}\")\n",
    "\n",
    "# Remove rows with NaN values\n",
    "barrier_events_clean = barrier_events.dropna()\n",
    "print(f\"\\nShape after dropping NaN: {barrier_events_clean.shape}\")\n",
    "\n",
    "# Use the close prices from dollar bars dataset as the price bars for the indicator matrix.\n",
    "close_prices = pdata1[['close']].copy() \n",
    "\n",
    "\n",
    "# Create the indicator matrix\n",
    "triple_barrier_ind_mat = bootstrapping.get_ind_matrix(barrier_events_clean, close_prices)\n",
    "# MlFinlab can also get average label uniqueness on the indicator matrix\n",
    "ind_mat_uniqueness = bootstrapping.get_ind_mat_average_uniqueness(\n",
    "     triple_barrier_ind_mat\n",
    ")\n",
    "av_unique = concurrent.get_av_uniqueness_from_triple_barrier(\n",
    "     pd.DataFrame(barrier_events_clean), close_prices, num_threads=1\n",
    ")\n",
    "# Draw sequential bootstrap\n",
    "bootstrapping.seq_bootstrap(\n",
    "     triple_barrier_ind_mat, sample_length=4, warmup_samples=[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "563f6fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "date_time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cum_vol",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cum_dollar",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cum_ticks",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2d8d4f9f-3c40-4288-a2c7-ef674a979d69",
       "rows": [
        [
         "2015-01-01 23:00:23.723000",
         "2053.0",
         "2056.75",
         "2051.0",
         "2056.75",
         "34102",
         "70001096.75",
         "8478"
        ],
        [
         "2015-01-02 07:07:35.156000",
         "2056.75",
         "2067.25",
         "2056.25",
         "2064.0",
         "33968",
         "70010061.25",
         "14514"
        ],
        [
         "2015-01-02 09:35:57.204000",
         "2064.0",
         "2067.25",
         "2058.75",
         "2060.5",
         "33972",
         "70087834.25",
         "16152"
        ],
        [
         "2015-01-02 12:59:42.176000",
         "2060.5",
         "2062.0",
         "2057.75",
         "2061.0",
         "33985",
         "70006169.75",
         "15502"
        ],
        [
         "2015-01-02 14:19:33.847000",
         "2061.0",
         "2064.25",
         "2058.75",
         "2063.75",
         "33958",
         "70000723.25",
         "12332"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>cum_vol</th>\n",
       "      <th>cum_dollar</th>\n",
       "      <th>cum_ticks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 23:00:23.723</th>\n",
       "      <td>2053.00</td>\n",
       "      <td>2056.75</td>\n",
       "      <td>2051.00</td>\n",
       "      <td>2056.75</td>\n",
       "      <td>34102</td>\n",
       "      <td>70001096.75</td>\n",
       "      <td>8478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 07:07:35.156</th>\n",
       "      <td>2056.75</td>\n",
       "      <td>2067.25</td>\n",
       "      <td>2056.25</td>\n",
       "      <td>2064.00</td>\n",
       "      <td>33968</td>\n",
       "      <td>70010061.25</td>\n",
       "      <td>14514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 09:35:57.204</th>\n",
       "      <td>2064.00</td>\n",
       "      <td>2067.25</td>\n",
       "      <td>2058.75</td>\n",
       "      <td>2060.50</td>\n",
       "      <td>33972</td>\n",
       "      <td>70087834.25</td>\n",
       "      <td>16152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 12:59:42.176</th>\n",
       "      <td>2060.50</td>\n",
       "      <td>2062.00</td>\n",
       "      <td>2057.75</td>\n",
       "      <td>2061.00</td>\n",
       "      <td>33985</td>\n",
       "      <td>70006169.75</td>\n",
       "      <td>15502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 14:19:33.847</th>\n",
       "      <td>2061.00</td>\n",
       "      <td>2064.25</td>\n",
       "      <td>2058.75</td>\n",
       "      <td>2063.75</td>\n",
       "      <td>33958</td>\n",
       "      <td>70000723.25</td>\n",
       "      <td>12332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            open     high      low    close  cum_vol   \n",
       "date_time                                                              \n",
       "2015-01-01 23:00:23.723  2053.00  2056.75  2051.00  2056.75    34102  \\\n",
       "2015-01-02 07:07:35.156  2056.75  2067.25  2056.25  2064.00    33968   \n",
       "2015-01-02 09:35:57.204  2064.00  2067.25  2058.75  2060.50    33972   \n",
       "2015-01-02 12:59:42.176  2060.50  2062.00  2057.75  2061.00    33985   \n",
       "2015-01-02 14:19:33.847  2061.00  2064.25  2058.75  2063.75    33958   \n",
       "\n",
       "                          cum_dollar  cum_ticks  \n",
       "date_time                                        \n",
       "2015-01-01 23:00:23.723  70001096.75       8478  \n",
       "2015-01-02 07:07:35.156  70010061.25      14514  \n",
       "2015-01-02 09:35:57.204  70087834.25      16152  \n",
       "2015-01-02 12:59:42.176  70006169.75      15502  \n",
       "2015-01-02 14:19:33.847  70000723.25      12332  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata1.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MlFinLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
